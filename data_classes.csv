,Project,File,Class,Code
0,data,src-test.KafkaUnit,KafkaUnit,"public class KafkaUnit { private KafkaServer kafkaServer; private EmbeddedZookeeper zkServer; private ZkUtils zkUtils; private KafkaProducer<String, String> producer; private static final String ZK_HOST = ""127.0.0.1""; private static final String KAFKA_HOST = ""127.0.0.1""; private static final int KAFKA_PORT = 9092; public KafkaUnit() { } public void setUp() throws IOException { zkServer = new EmbeddedZookeeper(); String zkConnect = ZK_HOST + "":"" + zkServer.port(); ZkClient zkClient = new ZkClient(zkConnect, 30000, 30000, ZKStringSerializer$.MODULE$); zkUtils = ZkUtils.apply(zkClient, false); Properties brokerProps = new Properties(); brokerProps.setProperty(""zookeeper.connect"", zkConnect); brokerProps.setProperty(""broker.id"", ""0""); brokerProps.setProperty(""log.dirs"", Files.createTempDirectory(""kafka-"").toAbsolutePath().toString()); brokerProps.setProperty(""listeners"", String.format(""PLAINTEXT: KafkaConfig config = new KafkaConfig(brokerProps); MockTime mock = new MockTime(); kafkaServer = TestUtils.createServer(config, mock); createProducer(); } public void tearDown() { closeProducer(); kafkaServer.shutdown(); zkUtils.close(); zkServer.shutdown(); } public void createTopic(String topicName) { AdminUtils.createTopic(zkUtils, topicName, 1, 1, new Properties(), RackAwareMode.Disabled$.MODULE$); } public int getKafkaPort() { return KAFKA_PORT; } private void createProducer() { Properties producerProps = new Properties(); producerProps.setProperty(BOOTSTRAP_SERVERS_CONFIG, KAFKA_HOST + "":"" + KAFKA_PORT); producerProps.setProperty(KEY_SERIALIZER_CLASS_CONFIG, ""org.apache.kafka.common.serialization.StringSerializer""); producerProps.setProperty(VALUE_SERIALIZER_CLASS_CONFIG, ""org.apache.kafka.common.serialization.StringSerializer""); producer = new KafkaProducer<>(producerProps); } public void createProducer(Serializer keySerializer, Serializer valueSerializer) { Properties producerProps = new Properties(); producerProps.setProperty(BOOTSTRAP_SERVERS_CONFIG, KAFKA_HOST + "":"" + KAFKA_PORT); producer = new KafkaProducer<>(producerProps, keySerializer, valueSerializer); } public void sendMessage(ProducerRecord producerRecord) throws InterruptedException, ExecutionException, TimeoutException { producer.send(producerRecord).get(10, TimeUnit.SECONDS); } private void closeProducer() { producer.close(); } }"
1,data,src-test.KafkaUnitRule,KafkaUnitRule,public class KafkaUnitRule extends ExternalResource { private final KafkaUnit kafkaUnit; public KafkaUnitRule() { this.kafkaUnit = new KafkaUnit(); } @Override public void before() throws IOException { kafkaUnit.setUp(); } @Override public void after() { kafkaUnit.tearDown(); } public KafkaUnit getKafkaUnit() { return this.kafkaUnit; } }
2,data,src-test.NullRecordTranslator,NullRecordTranslator,"public class NullRecordTranslator<K, V> implements RecordTranslator<K, V> { @Override public List<Object> apply(ConsumerRecord<K, V> record) { return null; } @Override public Fields getFieldsFor(String stream) { return new Fields(""topic"", ""key"", ""value""); } @Override public List<String> streams() { return Collections.singletonList(""default""); } } "
3,data,src-test.bolt.KafkaBoltTest,KafkaBoltTest,"public class KafkaBoltTest { private static final Logger LOG = LoggerFactory.getLogger(KafkaBoltTest.class); @SuppressWarnings({ ""unchecked"", ""serial"" }) @Test public void testSimple() { final KafkaProducer<String, String> producer = mock(KafkaProducer.class); when(producer.send((ProducerRecord<String,String>)any(), (Callback)any())).thenAnswer(new Answer<Object>() { @Override public Object answer(InvocationOnMock invocation) throws Throwable { Callback c = (Callback)invocation.getArguments()[1]; c.onCompletion(null, null); return null; } }); KafkaBolt<String, String> bolt = new KafkaBolt<String, String>() { @Override protected KafkaProducer<String, String> mkProducer(Properties props) { return producer; } }; bolt.withTopicSelector(""MY_TOPIC""); OutputCollector collector = mock(OutputCollector.class); TopologyContext context = mock(TopologyContext.class); Map<String, Object> conf = new HashMap<>(); bolt.prepare(conf, context, collector); MkTupleParam param = new MkTupleParam(); param.setFields(""key"", ""message""); Tuple testTuple = Testing.testTuple(Arrays.asList(""KEY"", ""VALUE""), param); bolt.execute(testTuple); verify(producer).send(argThat(new ArgumentMatcher<ProducerRecord<String, String>>() { @Override public boolean matches(Object argument) { LOG.info(""GOT {} ->"", argument); ProducerRecord<String, String> arg = (ProducerRecord<String, String>) argument; LOG.info("" {} {} {}"", arg.topic(), arg.key(), arg.value()); return ""MY_TOPIC"".equals(arg.topic()) && ""KEY"".equals(arg.key()) && ""VALUE"".equals(arg.value()); } }), any(Callback.class)); verify(collector).ack(testTuple); } } "
